{"class":"org.apache.spark.ml.feature.Tokenizer","timestamp":1697905190183,"sparkVersion":"3.5.0","uid":"tok_2dae9ea8cc53","paramMap":{"inputCol":"value","outputCol":"words"},"defaultParamMap":{"outputCol":"tok_2dae9ea8cc53__output"}}
